{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing a chat dialogue as one feature\n",
    "\n",
    "Notebook includes inferences on streaming observational feature space.\n",
    "\n",
    "The areas to target at retrieving features during streaming (or unique to each session interaction) includes:\n",
    "1. Dialogue \n",
    "    - Candidate's speech behaviour throughout the conversation \n",
    "2. Candidate's input form details \n",
    "\n",
    "The first section includes general analysis on text dialogue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue\n",
    "\n",
    "To mock live events, chat dialogue from `li2017dailydialog/daily_dialog` (https://huggingface.co/datasets/li2017dailydialog/daily_dialog) on huggingface was used for inferening and model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dialogue Intention vs. Emotional Intensity** \n",
    "\n",
    "Instead of having to transform the list of sequences every instance, this section targets at finding the dialogue features that is able to describe the dialogue's context. This could be another way of having to use vector embeddings of the text corpus. \n",
    "\n",
    "Target is that you want to find whether neutral emotions should be expected vs. emotion intensity \n",
    "\n",
    "**Backgroun notes**\n",
    "Features include the user's intent or actions labelled as `act` and emotion as `emotion` in the dataset. \n",
    "The possible categories of user's intent include `inform`, `question`, `directive` and `commissive`. To clarify the difference between `directive` and `commisive` speech:\n",
    "\n",
    "| **Aspect**          | **Directive Speech Acts**                   | **Commissive Speech Acts**                |\n",
    "|---------------------|---------------------------------------------|------------------------------------------|\n",
    "| **Purpose**         | To get the listener to do something.        | To commit the speaker to do something.   |\n",
    "| **Examples**        | Request, command, suggestion, advice.       | Promise, offer, vow, guarantee.          |\n",
    "| **Speaker's Role**  | Directs the listenerâ€™s actions.             | Commits the speaker to future actions.   |\n",
    "| **Listener's Role** | Listener is expected to perform the action. | No direct expectation from the listener. |\n",
    "\n",
    "I guess and expect that a dialogue's happiness counts relationship must be linear to commissive speech counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways in using this dataset in application (inferencing stage - assisting the agent's emotions)\n",
    "1. full chat dialogue interpreting (dialogue vs chunks of messages) to evaluate an agent's expressiveness or behaviour \n",
    "2. expected intent / emotion to return (by preprocessing and collecting every second response )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analytics: interpreting as full dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"li2017dailydialog/daily_dialog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dialog', 'act', 'emotion'],\n",
       "    num_rows: 12118\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "concatenate_datasets([data[\"train\"], data[\"validation\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 2, 2, 2, 3, 4, 1, 3, 4],\n",
       " [2, 1, 2, 2, 1, 1],\n",
       " [2, 1, 2, 1, 1],\n",
       " [2, 1, 1, 1],\n",
       " [2, 1, 2, 1, 1, 2, 1, 3, 4]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]['act']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modelling problem here can be defined to construct a predictor / indicator that returns the likelihood of an emotional intensity given the dialogue action and emotional states (Note that emotional states of both users are taken into account to represent the dilaogue's expressive / emotion state). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing: Transforming the action and emotes to multiclass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding by the number of actions (treating the problem as a multi-label classification)\n",
    "\n",
    "emote_input_config = ['noemote', 'anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n",
    "max_right_pad = 35\n",
    "\n",
    "def emote_transform(x):\n",
    "    # transforms the labels to -1 for negative and 1 for positive intensity\n",
    "    # negative (1, 2, 4, 5) and positive (4, 6)\n",
    "    for i in x:\n",
    "        yield 0 if i == 0 else 1\n",
    "\n",
    "def padding(input_lists, pad_value=-1, max_length=max_right_pad):\n",
    "    # Find the maximum length of the sublists\n",
    "    max_length = max(len(lst) for lst in input_lists)\n",
    "\n",
    "    # Create a NumPy array with the desired shape, filled with the pad_value\n",
    "    padded_array = np.full((len(input_lists), max_length), pad_value)\n",
    "\n",
    "    # Fill in the original values\n",
    "    for i, lst in enumerate(input_lists):\n",
    "        padded_array[i, :len(lst)] = lst\n",
    "\n",
    "    return padded_array\n",
    "\n",
    "data = data.add_column('padded_act', list(padding(data['act'])))\n",
    "data = data.add_column('emote_mu', [np.mean(list(emote_transform(x))) for x in data['emotion']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Dialogue features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The act column has been padded to the right with -1, and the emote_mu column has been added with the mean intensity of the emotion\n",
    "# Intention here is to convert the act column into a one-hot encoding and the emote_mu column into a binary classification\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "intent_map = ['no_intent', 'inform', 'question', 'directive', 'commisive']\n",
    "emote_map = ['noemote', 'anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']\n",
    "\n",
    "df = data.to_pandas()\n",
    "\n",
    "dummies = pd.get_dummies(df.explode('act')['act'], prefix='act', dtype=int)\n",
    "count_df = dummies.groupby(dummies.index).sum()\n",
    "e_dummies = pd.get_dummies(df.explode('emotion')['emotion'], prefix='emote', dtype=int)\n",
    "e_count_df = e_dummies.groupby(e_dummies.index).sum()\n",
    "\n",
    "df = pd.concat([df, count_df], axis=1)\n",
    "df = pd.concat([df, e_count_df], axis=1)\n",
    "# Size of the dialogue\n",
    "df['dialog_size'] = df['dialog'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dialog_size'] = df['dialog'].str.len()\n",
    "df['emotion_intensity'] = df['emote_0'] / df['dialog_size'] # highest = 1, the higher the more neutral / emotionless the speech is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when dividing the act / emotion counts by the dialog size, we get the proportion of the act / emotion in the dialogue aka it should transform them to probabilities summing to 1\n",
    "\n",
    "# defining the column labels\n",
    "act_col = [f\"act_{i}\" for i in range(1, len(intent_map))]\n",
    "emote_col = [f\"emote_{i}\" for i in range(len(emote_map))]\n",
    "# normalizing the act and emotion columns by the dialog size\n",
    "df[act_col] /= df['dialog_size'].values[:, None]\n",
    "df[emote_col] /= df['dialog_size'].values[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.600000\n",
       "1        0.833333\n",
       "2        1.000000\n",
       "3        1.000000\n",
       "4        0.777778\n",
       "           ...   \n",
       "11113    0.777778\n",
       "11114    0.833333\n",
       "11115    0.812500\n",
       "11116    1.000000\n",
       "11117    1.000000\n",
       "Name: emote_0, Length: 11118, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emote_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([j for i in df['act'].values for j in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emote_0</th>\n",
       "      <th>emote_1</th>\n",
       "      <th>emote_2</th>\n",
       "      <th>emote_3</th>\n",
       "      <th>emote_4</th>\n",
       "      <th>emote_5</th>\n",
       "      <th>emote_6</th>\n",
       "      <th>act_1</th>\n",
       "      <th>act_2</th>\n",
       "      <th>act_3</th>\n",
       "      <th>act_4</th>\n",
       "      <th>dialog_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>emote_0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.185839</td>\n",
       "      <td>-0.131410</td>\n",
       "      <td>-0.072033</td>\n",
       "      <td>-0.882315</td>\n",
       "      <td>-0.191184</td>\n",
       "      <td>-0.211492</td>\n",
       "      <td>-0.214280</td>\n",
       "      <td>0.229690</td>\n",
       "      <td>0.108448</td>\n",
       "      <td>-0.031595</td>\n",
       "      <td>0.051299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_1</th>\n",
       "      <td>-0.185839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>-0.005069</td>\n",
       "      <td>-0.078864</td>\n",
       "      <td>0.037469</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>-0.069291</td>\n",
       "      <td>-0.013118</td>\n",
       "      <td>-0.004142</td>\n",
       "      <td>-0.023229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_2</th>\n",
       "      <td>-0.131410</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002115</td>\n",
       "      <td>-0.044883</td>\n",
       "      <td>-0.017038</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.092071</td>\n",
       "      <td>-0.050558</td>\n",
       "      <td>-0.055881</td>\n",
       "      <td>-0.038747</td>\n",
       "      <td>-0.054836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_3</th>\n",
       "      <td>-0.072033</td>\n",
       "      <td>-0.005069</td>\n",
       "      <td>-0.002115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018843</td>\n",
       "      <td>-0.005839</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>-0.034707</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.011796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_4</th>\n",
       "      <td>-0.882315</td>\n",
       "      <td>-0.078864</td>\n",
       "      <td>-0.044883</td>\n",
       "      <td>-0.018843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.069683</td>\n",
       "      <td>-0.027849</td>\n",
       "      <td>0.153229</td>\n",
       "      <td>-0.202316</td>\n",
       "      <td>-0.069376</td>\n",
       "      <td>0.062766</td>\n",
       "      <td>-0.026519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_5</th>\n",
       "      <td>-0.191184</td>\n",
       "      <td>0.037469</td>\n",
       "      <td>-0.017038</td>\n",
       "      <td>-0.005839</td>\n",
       "      <td>-0.069683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008370</td>\n",
       "      <td>0.056232</td>\n",
       "      <td>-0.091670</td>\n",
       "      <td>-0.003776</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>-0.048561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_6</th>\n",
       "      <td>-0.211492</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>-0.027849</td>\n",
       "      <td>-0.008370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102282</td>\n",
       "      <td>0.050265</td>\n",
       "      <td>-0.125610</td>\n",
       "      <td>-0.096317</td>\n",
       "      <td>0.009299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_1</th>\n",
       "      <td>-0.214280</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.092071</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.153229</td>\n",
       "      <td>0.056232</td>\n",
       "      <td>0.102282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.165500</td>\n",
       "      <td>-0.794508</td>\n",
       "      <td>-0.672977</td>\n",
       "      <td>-0.061544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_2</th>\n",
       "      <td>0.229690</td>\n",
       "      <td>-0.069291</td>\n",
       "      <td>-0.050558</td>\n",
       "      <td>-0.034707</td>\n",
       "      <td>-0.202316</td>\n",
       "      <td>-0.091670</td>\n",
       "      <td>0.050265</td>\n",
       "      <td>-0.165500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.384405</td>\n",
       "      <td>-0.469346</td>\n",
       "      <td>0.141934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_3</th>\n",
       "      <td>0.108448</td>\n",
       "      <td>-0.013118</td>\n",
       "      <td>-0.055881</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>-0.069376</td>\n",
       "      <td>-0.003776</td>\n",
       "      <td>-0.125610</td>\n",
       "      <td>-0.794508</td>\n",
       "      <td>-0.384405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704668</td>\n",
       "      <td>-0.021714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_4</th>\n",
       "      <td>-0.031595</td>\n",
       "      <td>-0.004142</td>\n",
       "      <td>-0.038747</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>0.062766</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>-0.096317</td>\n",
       "      <td>-0.672977</td>\n",
       "      <td>-0.469346</td>\n",
       "      <td>0.704668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dialog_size</th>\n",
       "      <td>0.051299</td>\n",
       "      <td>-0.023229</td>\n",
       "      <td>-0.054836</td>\n",
       "      <td>-0.011796</td>\n",
       "      <td>-0.026519</td>\n",
       "      <td>-0.048561</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>-0.061544</td>\n",
       "      <td>0.141934</td>\n",
       "      <td>-0.021714</td>\n",
       "      <td>-0.036188</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              emote_0   emote_1   emote_2   emote_3   emote_4   emote_5  \\\n",
       "emote_0      1.000000 -0.185839 -0.131410 -0.072033 -0.882315 -0.191184   \n",
       "emote_1     -0.185839  1.000000  0.011847 -0.005069 -0.078864  0.037469   \n",
       "emote_2     -0.131410  0.011847  1.000000 -0.002115 -0.044883 -0.017038   \n",
       "emote_3     -0.072033 -0.005069 -0.002115  1.000000 -0.018843 -0.005839   \n",
       "emote_4     -0.882315 -0.078864 -0.044883 -0.018843  1.000000 -0.069683   \n",
       "emote_5     -0.191184  0.037469 -0.017038 -0.005839 -0.069683  1.000000   \n",
       "emote_6     -0.211492  0.004559  0.000391 -0.001208 -0.027849 -0.008370   \n",
       "act_1       -0.214280  0.057445  0.092071  0.021277  0.153229  0.056232   \n",
       "act_2        0.229690 -0.069291 -0.050558 -0.034707 -0.202316 -0.091670   \n",
       "act_3        0.108448 -0.013118 -0.055881  0.004371 -0.069376 -0.003776   \n",
       "act_4       -0.031595 -0.004142 -0.038747 -0.002571  0.062766  0.015380   \n",
       "dialog_size  0.051299 -0.023229 -0.054836 -0.011796 -0.026519 -0.048561   \n",
       "\n",
       "              emote_6     act_1     act_2     act_3     act_4  dialog_size  \n",
       "emote_0     -0.211492 -0.214280  0.229690  0.108448 -0.031595     0.051299  \n",
       "emote_1      0.004559  0.057445 -0.069291 -0.013118 -0.004142    -0.023229  \n",
       "emote_2      0.000391  0.092071 -0.050558 -0.055881 -0.038747    -0.054836  \n",
       "emote_3     -0.001208  0.021277 -0.034707  0.004371 -0.002571    -0.011796  \n",
       "emote_4     -0.027849  0.153229 -0.202316 -0.069376  0.062766    -0.026519  \n",
       "emote_5     -0.008370  0.056232 -0.091670 -0.003776  0.015380    -0.048561  \n",
       "emote_6      1.000000  0.102282  0.050265 -0.125610 -0.096317     0.009299  \n",
       "act_1        0.102282  1.000000 -0.165500 -0.794508 -0.672977    -0.061544  \n",
       "act_2        0.050265 -0.165500  1.000000 -0.384405 -0.469346     0.141934  \n",
       "act_3       -0.125610 -0.794508 -0.384405  1.000000  0.704668    -0.021714  \n",
       "act_4       -0.096317 -0.672977 -0.469346  0.704668  1.000000    -0.036188  \n",
       "dialog_size  0.009299 -0.061544  0.141934 -0.021714 -0.036188     1.000000  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['emote_0', 'emote_1', 'emote_2', 'emote_3', 'emote_4', 'emote_5', 'emote_6', 'act_1', 'act_2', 'act_3', 'act_4', 'dialog_size']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    243.000000\n",
       "mean       0.196845\n",
       "std        0.332304\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.250000\n",
       "max        1.000000\n",
       "Name: emote_4, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am guessing that the more commissive the conversation is, the more likely it is for the conversation to have higher counts in the happiness emotion (or positive emotions in general), and this works the other way too. Let's see if this is true\n",
    "\n",
    "df[df['act_4'] >= 0.5]['emote_4'].describe() # commissive action >= 0.5 and happiness probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10875.000000\n",
       "mean         0.130029\n",
       "std          0.234148\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.166667\n",
       "max          1.000000\n",
       "Name: emote_4, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['act_4'] < 0.5]['emote_4'].describe() # commisive action < 0.5 and happiness probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_1</th>\n",
       "      <th>act_2</th>\n",
       "      <th>act_3</th>\n",
       "      <th>act_4</th>\n",
       "      <th>emote_0</th>\n",
       "      <th>emote_1</th>\n",
       "      <th>emote_2</th>\n",
       "      <th>emote_3</th>\n",
       "      <th>emote_4</th>\n",
       "      <th>emote_5</th>\n",
       "      <th>emote_6</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>act_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.126438</td>\n",
       "      <td>-0.801684</td>\n",
       "      <td>-0.670036</td>\n",
       "      <td>-0.209971</td>\n",
       "      <td>0.058970</td>\n",
       "      <td>0.084056</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.155443</td>\n",
       "      <td>0.041651</td>\n",
       "      <td>0.116353</td>\n",
       "      <td>0.122694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_2</th>\n",
       "      <td>-0.126438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.409742</td>\n",
       "      <td>-0.498170</td>\n",
       "      <td>0.210122</td>\n",
       "      <td>-0.070570</td>\n",
       "      <td>-0.037640</td>\n",
       "      <td>-0.026819</td>\n",
       "      <td>-0.190819</td>\n",
       "      <td>-0.081924</td>\n",
       "      <td>0.058722</td>\n",
       "      <td>-0.112684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_3</th>\n",
       "      <td>-0.801684</td>\n",
       "      <td>-0.409742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702450</td>\n",
       "      <td>0.114191</td>\n",
       "      <td>-0.013517</td>\n",
       "      <td>-0.053430</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>-0.077785</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>-0.139387</td>\n",
       "      <td>-0.072846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_4</th>\n",
       "      <td>-0.670036</td>\n",
       "      <td>-0.498170</td>\n",
       "      <td>0.702450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029743</td>\n",
       "      <td>-0.003588</td>\n",
       "      <td>-0.040209</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>0.019651</td>\n",
       "      <td>-0.109534</td>\n",
       "      <td>0.012707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_0</th>\n",
       "      <td>-0.209971</td>\n",
       "      <td>0.210122</td>\n",
       "      <td>0.114191</td>\n",
       "      <td>-0.029743</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.182269</td>\n",
       "      <td>-0.109553</td>\n",
       "      <td>-0.068137</td>\n",
       "      <td>-0.894725</td>\n",
       "      <td>-0.171812</td>\n",
       "      <td>-0.217418</td>\n",
       "      <td>-0.582810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_1</th>\n",
       "      <td>0.058970</td>\n",
       "      <td>-0.070570</td>\n",
       "      <td>-0.013517</td>\n",
       "      <td>-0.003588</td>\n",
       "      <td>-0.182269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025265</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>-0.081931</td>\n",
       "      <td>0.045374</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.002090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_2</th>\n",
       "      <td>0.084056</td>\n",
       "      <td>-0.037640</td>\n",
       "      <td>-0.053430</td>\n",
       "      <td>-0.040209</td>\n",
       "      <td>-0.109553</td>\n",
       "      <td>0.025265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002721</td>\n",
       "      <td>-0.040431</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.018849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_3</th>\n",
       "      <td>0.004483</td>\n",
       "      <td>-0.026819</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>-0.068137</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>-0.002721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022772</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>0.027631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_4</th>\n",
       "      <td>0.155443</td>\n",
       "      <td>-0.190819</td>\n",
       "      <td>-0.077785</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>-0.894725</td>\n",
       "      <td>-0.081931</td>\n",
       "      <td>-0.040431</td>\n",
       "      <td>-0.022772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071535</td>\n",
       "      <td>-0.021788</td>\n",
       "      <td>0.532266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_5</th>\n",
       "      <td>0.041651</td>\n",
       "      <td>-0.081924</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.019651</td>\n",
       "      <td>-0.171812</td>\n",
       "      <td>0.045374</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.071535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.130734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emote_6</th>\n",
       "      <td>0.116353</td>\n",
       "      <td>0.058722</td>\n",
       "      <td>-0.139387</td>\n",
       "      <td>-0.109534</td>\n",
       "      <td>-0.217418</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>-0.021788</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <td>0.122694</td>\n",
       "      <td>-0.112684</td>\n",
       "      <td>-0.072846</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>-0.582810</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.018849</td>\n",
       "      <td>0.027631</td>\n",
       "      <td>0.532266</td>\n",
       "      <td>0.130734</td>\n",
       "      <td>0.193988</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            act_1     act_2     act_3     act_4   emote_0   emote_1   emote_2  \\\n",
       "act_1    1.000000 -0.126438 -0.801684 -0.670036 -0.209971  0.058970  0.084056   \n",
       "act_2   -0.126438  1.000000 -0.409742 -0.498170  0.210122 -0.070570 -0.037640   \n",
       "act_3   -0.801684 -0.409742  1.000000  0.702450  0.114191 -0.013517 -0.053430   \n",
       "act_4   -0.670036 -0.498170  0.702450  1.000000 -0.029743 -0.003588 -0.040209   \n",
       "emote_0 -0.209971  0.210122  0.114191 -0.029743  1.000000 -0.182269 -0.109553   \n",
       "emote_1  0.058970 -0.070570 -0.013517 -0.003588 -0.182269  1.000000  0.025265   \n",
       "emote_2  0.084056 -0.037640 -0.053430 -0.040209 -0.109553  0.025265  1.000000   \n",
       "emote_3  0.004483 -0.026819  0.015053  0.005046 -0.068137 -0.000749 -0.002721   \n",
       "emote_4  0.155443 -0.190819 -0.077785  0.060219 -0.894725 -0.081931 -0.040431   \n",
       "emote_5  0.041651 -0.081924  0.004990  0.019651 -0.171812  0.045374 -0.013694   \n",
       "emote_6  0.116353  0.058722 -0.139387 -0.109534 -0.217418  0.016368  0.001459   \n",
       "emotion  0.122694 -0.112684 -0.072846  0.012707 -0.582810  0.002090  0.018849   \n",
       "\n",
       "          emote_3   emote_4   emote_5   emote_6   emotion  \n",
       "act_1    0.004483  0.155443  0.041651  0.116353  0.122694  \n",
       "act_2   -0.026819 -0.190819 -0.081924  0.058722 -0.112684  \n",
       "act_3    0.015053 -0.077785  0.004990 -0.139387 -0.072846  \n",
       "act_4    0.005046  0.060219  0.019651 -0.109534  0.012707  \n",
       "emote_0 -0.068137 -0.894725 -0.171812 -0.217418 -0.582810  \n",
       "emote_1 -0.000749 -0.081931  0.045374  0.016368  0.002090  \n",
       "emote_2 -0.002721 -0.040431 -0.013694  0.001459  0.018849  \n",
       "emote_3  1.000000 -0.022772 -0.000510  0.006871  0.027631  \n",
       "emote_4 -0.022772  1.000000 -0.071535 -0.021788  0.532266  \n",
       "emote_5 -0.000510 -0.071535  1.000000  0.007818  0.130734  \n",
       "emote_6  0.006871 -0.021788  0.007818  1.000000  0.193988  \n",
       "emotion  0.027631  0.532266  0.130734  0.193988  1.000000  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.explode('emotion')[act_col + emote_col + ['emotion']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "0    0.827613\n",
       "4    0.128278\n",
       "6    0.018355\n",
       "5    0.011116\n",
       "1    0.009487\n",
       "2    0.003476\n",
       "3    0.001675\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since the correlation between happiness and unknown was high, wanted to see if this is due to the dataset's quality where it contains more unknowns and happiness than other emotions or if there is a real correlation between the two\n",
    "\n",
    "df['emotion'].value_counts(normalize=True) # unknown emotions equips ~80% of the dataset jesus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "0    0.827613\n",
       "1    0.172387\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming the dataset again for binary classification: no emotion vs emotion\n",
    "df['emotion'] = np.where(df['emotion'] != 0, 1, 0)\n",
    "df['emotion'].value_counts(normalize=True) # Reviewing the emotionless vs emotional states again: 80% of the dataset is emotionless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "    Mean Absolute Error (MAE)  Mean Squared Error (MSE)  R^2 Score\n",
      "0                   0.176124                  0.087868   0.384122\n",
      "Eval\n",
      "    Mean Absolute Error (MAE)  Mean Squared Error (MSE)  R^2 Score\n",
      "0                   0.177608                  0.088171   0.381981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "seed = 42\n",
    "pred_cols = ['emote_0', 'emote_1', 'emote_2', 'emote_3', 'emote_4', 'emote_5', 'emote_6', 'act_1', 'act_2', 'act_3', 'act_4', 'dialog_size']\n",
    "\n",
    "X = df[pred_cols].values\n",
    "y = df['emotion'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=seed)\n",
    "\n",
    "def linear_regression(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fits a Linear Regression model and returns the model, predictions, and evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "    X_train: array-like or pandas DataFrame, shape (n_samples, n_features)\n",
    "        The training input samples.\n",
    "    y_train: array-like, shape (n_samples,)\n",
    "        The target values for training.\n",
    "\n",
    "    Returns:\n",
    "    model: LinearRegression\n",
    "        The fitted Linear Regression model.\n",
    "    predictions: array, shape (n_samples,)\n",
    "        The predicted values for the training data.\n",
    "    metrics: dict\n",
    "        A dictionary containing the evaluation metrics (MAE, MSE, R^2).\n",
    "    \"\"\"\n",
    "    # Initialize the Linear Regression model\n",
    "    model = linear_model.LinearRegression()\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on both training and testing data\n",
    "    predictions_train = model.predict(X_train)\n",
    "    predictions_test = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for testing data\n",
    "    mae_test = mean_absolute_error(y_test, predictions_test)\n",
    "    mse_test = mean_squared_error(y_test, predictions_test)\n",
    "\n",
    "    # Store metrics in dictionaries\n",
    "    metrics_train = pd.DataFrame([{\n",
    "        'Mean Absolute Error (MAE)': mean_absolute_error(y_train, predictions_train),\n",
    "        'Mean Squared Error (MSE)': mean_squared_error(y_train, predictions_train),\n",
    "        'R^2 Score': r2_score(y_train, predictions_train)\n",
    "    }])\n",
    "\n",
    "    metrics_test = pd.DataFrame([{\n",
    "        'Mean Absolute Error (MAE)': mae_test,\n",
    "        'Mean Squared Error (MSE)': mse_test,\n",
    "        'R^2 Score': r2_score(y_test, predictions_test)\n",
    "    }])\n",
    "\n",
    "    print('Train\\n', metrics_train)\n",
    "    print('Eval\\n', metrics_test)\n",
    "\n",
    "    return model\n",
    "\n",
    "lr = linear_regression(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- higher towards 1 predictions = likelihood of no emotions (maybe in usage 1-pred = neutral prob)\n",
    "- lower towards 0 (or neg) predictions= likelihood of emotions existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09931345])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([[2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14866205])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([[0, 10, 0, 0, 0, 0, 0,10, 0, 0, 0, 10]]) # 10 angry utters over 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.92351798])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([[20, 2, 0, 0, 0, 0, 0,10, 0, 0, 0, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82100351])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([np.zeros(len(pred_cols))]) # Hypothetical Scenario: zero emotions inferenced from the previous speech and NAN speech intent returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63875645])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([np.ones(len(pred_cols))]) # Hypothetical Scenario: At least one emote was felt and intent was returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up code with proper training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dialog(split_type):\n",
    "    data = load_dataset(\"li2017dailydialog/daily_dialog\", split=split_type)\n",
    "    df = data.to_pandas()\n",
    "\n",
    "    dummies = pd.get_dummies(df.explode('act')['act'], prefix='act', dtype=int)\n",
    "    count_df = dummies.groupby(dummies.index).sum()\n",
    "    e_dummies = pd.get_dummies(df.explode('emotion')['emotion'], prefix='emote', dtype=int)\n",
    "    e_count_df = e_dummies.groupby(e_dummies.index).sum()\n",
    "    df = pd.concat([df, count_df], axis=1)\n",
    "    df = pd.concat([df, e_count_df], axis=1)\n",
    "    df['dialog_size'] = [len(i) for i in df['dialog']]\n",
    "    df['emotion_intensity'] = df['emote_0'] / df['dialog_size'] # highest = 1, the higher the more neutral the dialogue should be\n",
    "\n",
    "    return df[pred_cols].values, df['emotion_intensity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_dialog(split_type='train')\n",
    "x_valid, y_valid = load_dialog(split_type='validation')\n",
    "x_test, y_test = load_dialog(split_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "    Mean Absolute Error (MAE)  Mean Squared Error (MSE)  R^2 Score\n",
      "0                   0.076375                  0.014731   0.770187\n",
      "Eval\n",
      "    Mean Absolute Error (MAE)  Mean Squared Error (MSE)  R^2 Score\n",
      "0                   0.058813                  0.007901   0.755051\n"
     ]
    }
   ],
   "source": [
    "lr = linear_regression(x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7710130835412832, 0.7550514991831193, 0.7701873983454256)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(x_test, y_test), lr.score(x_valid, y_valid), lr.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/march/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88     14429\n",
      "           1       0.48      0.75      0.59      3005\n",
      "\n",
      "    accuracy                           0.82     17434\n",
      "   macro avg       0.71      0.79      0.73     17434\n",
      "weighted avg       0.86      0.82      0.83     17434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE  # For oversampling\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "pred_cols = ['emote_0', 'emote_1', 'emote_2', 'emote_3', 'emote_4', 'emote_5', 'emote_6', 'act_1', 'act_2', 'act_3', 'act_4', 'dialog_size']\n",
    "\n",
    "X = df[pred_cols].values\n",
    "y = df['emotion'].values\n",
    "\n",
    "# 1. Train-Test Split (Maintains class distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n",
    "\n",
    "# 2. Apply SMOTE (Oversampling minority class in training set)\n",
    "smote = SMOTE(random_state=SEED)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Scale features AFTER splitting (to avoid data leakage)\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 4. Train Model (Using class weights to handle imbalance)\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "model = LogisticRegression(class_weight={0: class_weights[0], 1: class_weights[1]})\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 5. Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_emotion': 0.06377385366365329, 'emotional': 0.9362261463363467}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {0: \"no_emotion\", 1: \"emotional\"}\n",
    "\n",
    "dict(zip(label_map.values(), *model.predict_proba(X_test[:1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Dialogue for predicting the next intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returning intent conditioned to the full dialogue is difficult and may not be useful... \n",
    "But we can preprocess this dataset further to represent it as a paired speech dataset where every second intent will be the predicting variable and the inputs would be the utterance (encoded with `sentence_transformers`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"li2017dailydialog/daily_dialog\", split='train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation: dialogue to paired chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_map = {\n",
    "    'dialog': 'a',\n",
    "    'act': 'act_a',\n",
    "    'emotion': 'emote_a'\n",
    "}\n",
    "new_col = ['b', 'act_b', 'emote_b']\n",
    "\n",
    "def transform_to_pairs(df):\n",
    "    \"\"\" This method doesnt preserve the dialogue ids and randomnizes. But puts into paired columns efficiently. \"\"\"\n",
    "\n",
    "    explode = df.explode(['dialog', 'act', 'emotion']).reset_index(names='dialog_id')\n",
    "    explode['pair_id'] = explode.groupby('dialog_id').cumcount() % 2\n",
    "    # Pivot the table while avoiding duplicate index issues\n",
    "    df_paired = explode.pivot_table(index='dialog_id', columns='pair_id', values=['dialog', 'emotion', 'act'], aggfunc='first')\n",
    "    # Flatten MultiIndex columns and rename using col_names_map\n",
    "    df_paired.columns = [col_names_map[col[0]] if col[1] == 0 else new_col[list(col_names_map.keys()).index(col[0])] for col in df_paired.columns]\n",
    "    df_paired.reset_index(drop=True, inplace=True)\n",
    "    return df_paired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df =transform_to_pairs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_a</th>\n",
       "      <th>act_b</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>emote_a</th>\n",
       "      <th>emote_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>You know that is tempting but is really not g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Can you do push-ups ?</td>\n",
       "      <td>Of course I can . It's a piece of cake ! Beli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Can you study with the radio on ?</td>\n",
       "      <td>No , I listen to background music .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Are you all right ?</td>\n",
       "      <td>I will be all right soon . I was terrified wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey John , nice skates . Are they new ?</td>\n",
       "      <td>Yeah , I just got them . I started playing ic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>How was your education going on in Australia ?</td>\n",
       "      <td>I'm going to graduate this summer .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you have any particular hobbies , Tom ?</td>\n",
       "      <td>Oh , yes . I love playing badminton , table t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>What â€™ s the plot of your new movie ?</td>\n",
       "      <td>It â€™ s a story about a policemen who is inves...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Who's that old lady trimming the trees ?</td>\n",
       "      <td>She's my grandma .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Mom . My legs are killing me .</td>\n",
       "      <td>Hold on . We will be successful right away .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   act_a act_b                                                  a  \\\n",
       "0      3     4  Say , Jim , how about going for a few beers af...   \n",
       "1      2     1                             Can you do push-ups ?    \n",
       "2      2     1                 Can you study with the radio on ?    \n",
       "3      2     1                               Are you all right ?    \n",
       "4      2     1           Hey John , nice skates . Are they new ?    \n",
       "..   ...   ...                                                ...   \n",
       "95     2     1    How was your education going on in Australia ?    \n",
       "96     2     1        Do you have any particular hobbies , Tom ?    \n",
       "97     2     1             What â€™ s the plot of your new movie ?    \n",
       "98     2     1          Who's that old lady trimming the trees ?    \n",
       "99     3     4                    Mom . My legs are killing me .    \n",
       "\n",
       "                                                    b emote_a emote_b  \n",
       "0    You know that is tempting but is really not g...       0       0  \n",
       "1    Of course I can . It's a piece of cake ! Beli...       0       0  \n",
       "2                No , I listen to background music .        0       0  \n",
       "3    I will be all right soon . I was terrified wh...       0       0  \n",
       "4    Yeah , I just got them . I started playing ic...       0       0  \n",
       "..                                                ...     ...     ...  \n",
       "95               I'm going to graduate this summer .        0       0  \n",
       "96   Oh , yes . I love playing badminton , table t...       0       0  \n",
       "97   It â€™ s a story about a policemen who is inves...       0       0  \n",
       "98                                She's my grandma .        0       0  \n",
       "99      Hold on . We will be successful right away .        0       0  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3780f192573459899be2221708881fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform_dataset(row):\n",
    "    # Extract the columns and also preserves the dialogue ids. Uses zip method\n",
    "\n",
    "    dialog = row['dialog']\n",
    "    act = row['act']\n",
    "    emotion = row['emotion']\n",
    "    # Pair them\n",
    "    paired = list(zip(dialog[::2], dialog[1::2], emotion[::2], emotion[1::2], act[::2], act[1::2]))\n",
    "    dialog_a, dialog_b, emote_a, emote_b, act_a, act_b = zip(*paired)\n",
    "\n",
    "    return {\n",
    "        'dialog_a': list(dialog_a),\n",
    "        'dialog_b': list(dialog_b),\n",
    "        'emote_a': list(emote_a),\n",
    "        'emote_b': list(emote_b),\n",
    "        'act_a': list(act_a),\n",
    "        'act_b': list(act_b),\n",
    "        'dialogue_size': len(dialog)\n",
    "    }\n",
    "\n",
    "def prepare_dataset(ds):\n",
    "\n",
    "    new = ds.map(transform_dataset, remove_columns=['dialog', 'act', 'emotion'])\n",
    "    new_df = new.to_pandas().explode(['dialog_a', 'dialog_b', 'emote_a', 'emote_b', 'act_a', 'act_b'])\n",
    "    return new_df\n",
    "\n",
    "new_cols = ['dialog_a', 'dialog_b', 'emote_a', 'emote_b', 'act_a', 'act_b']\n",
    "new_ds = ds.map(transform_dataset, remove_columns=['dialog', 'act', 'emotion'])\n",
    "new = new_ds.to_pandas().explode(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog_a</th>\n",
       "      <th>dialog_b</th>\n",
       "      <th>emote_a</th>\n",
       "      <th>emote_b</th>\n",
       "      <th>act_a</th>\n",
       "      <th>act_b</th>\n",
       "      <th>dialogue_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>You know that is tempting but is really not g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What do you mean ? It will help us to relax .</td>\n",
       "      <td>Do you really think so ? I don't . It will ju...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I guess you are right.But what shall we do ? ...</td>\n",
       "      <td>I suggest a walk over to the gym where we can...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's a good idea . I hear Mary and Sally of...</td>\n",
       "      <td>Sounds great to me ! If they are willing , we...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good.Let ' s go now .</td>\n",
       "      <td>All right .</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Did you do you own stunts in the movie ?</td>\n",
       "      <td>I wanted to , but my insurance company wouldn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Thank you very much for doing this interview .</td>\n",
       "      <td>My pleasure . Have you seen the movie yet ?</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Who's that old lady trimming the trees ?</td>\n",
       "      <td>She's my grandma .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>She's looks very healthy.How old is she ?</td>\n",
       "      <td>92 .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Mom . My legs are killing me .</td>\n",
       "      <td>Hold on . We will be successful right away .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dialog_a  \\\n",
       "0   Say , Jim , how about going for a few beers af...   \n",
       "0      What do you mean ? It will help us to relax .    \n",
       "0    I guess you are right.But what shall we do ? ...   \n",
       "0    That's a good idea . I hear Mary and Sally of...   \n",
       "0                              Good.Let ' s go now .    \n",
       "..                                                ...   \n",
       "97          Did you do you own stunts in the movie ?    \n",
       "97    Thank you very much for doing this interview .    \n",
       "98          Who's that old lady trimming the trees ?    \n",
       "98         She's looks very healthy.How old is she ?    \n",
       "99                    Mom . My legs are killing me .    \n",
       "\n",
       "                                             dialog_b emote_a emote_b act_a  \\\n",
       "0    You know that is tempting but is really not g...       0       0     3   \n",
       "0    Do you really think so ? I don't . It will ju...       0       0     2   \n",
       "0    I suggest a walk over to the gym where we can...       0       0     2   \n",
       "0    Sounds great to me ! If they are willing , we...       4       4     4   \n",
       "0                                        All right .        4       4     3   \n",
       "..                                                ...     ...     ...   ...   \n",
       "97   I wanted to , but my insurance company wouldn...       0       0     2   \n",
       "97       My pleasure . Have you seen the movie yet ?        4       4     1   \n",
       "98                                She's my grandma .        0       0     2   \n",
       "98                                              92 .        0       0     2   \n",
       "99      Hold on . We will be successful right away .        0       0     3   \n",
       "\n",
       "   act_b  dialogue_size  \n",
       "0      4             10  \n",
       "0      2             10  \n",
       "0      3             10  \n",
       "0      1             10  \n",
       "0      4             10  \n",
       "..   ...            ...  \n",
       "97     1             11  \n",
       "97     2             11  \n",
       "98     1              4  \n",
       "98     1              4  \n",
       "99     4              2  \n",
       "\n",
       "[344 rows x 7 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_a_1</th>\n",
       "      <th>act_a_2</th>\n",
       "      <th>act_a_3</th>\n",
       "      <th>act_a_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    act_a_1  act_a_2  act_a_3  act_a_4\n",
       "0         0        2        2        1\n",
       "1         1        2        0        0\n",
       "2         0        2        0        0\n",
       "3         1        1        0        0\n",
       "4         2        2        0        0\n",
       "..      ...      ...      ...      ...\n",
       "95        0        2        1        0\n",
       "96        1        3        0        0\n",
       "97        1        4        0        0\n",
       "98        0        2        0        0\n",
       "99        0        0        1        0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(new['act_a'], prefix='act_a', dtype=int).groupby(new.index).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "march",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
